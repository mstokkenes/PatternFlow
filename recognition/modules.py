# -*- coding: utf-8 -*-
"""modules.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q1gdMhdv0C0HusM4-WN_DLI5EEYv93Ay
"""

import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow import keras
from keras import layers
import numpy as np

def context_module(level, input_layer):

  n_filters = 2**(level-1) * 16
  
  cont = tfa.layers.InstanceNormalization()(input_layer)
  cont = layers.LeakyReLU(0.01)(cont)
  cont = layers.Conv2D(n_filters, (3, 3), padding = "same")(cont)

  cont = layers.Dropout(rate = 0.3)(cont)

  cont = tfa.layers.InstanceNormalization()(cont)
  cont = layers.LeakyReLU(0.01)(cont)
  cont = layers.Conv2D(n_filters, (3, 3), padding = "same")(cont)

  return cont

def pool(level, input_layer):

  n_filters = 2**(level-1) * 16

  pool = layers.Conv2D(n_filters, (3, 3), (2, 2), padding = "same")(input_layer)
  pool = layers.LeakyReLU(0.01)(pool)

  return pool

def upsampling_module(level, input_layer):

  n_filters = 2**(level-1) * 16

  ups = tf.keras.layers.UpSampling2D()(input_layer)
  ups = tf.keras.layers.Conv2D(n_filters, (3, 3) , padding = "same")(ups)
  ups = tf.keras.layers.LeakyReLU(0.01)(ups) 

  return ups

def localization_module(level, input_layer):

    n_filters = 2**(level-2) * 16
    
    loc = layers.Conv2D(n_filters, (3, 3), padding = "same")(input_layer)
    loc = tfa.layers.InstanceNormalization()(loc)
    loc = layers.LeakyReLU(0.01)(loc)
    loc = layers.Conv2D(n_filters, (1, 1), padding = "same")(loc)
    loc = tfa.layers.InstanceNormalization()(loc)
    loc = layers.LeakyReLU(0.01)(loc)

    return loc

def improved_UNET():

  input = layers.Input(shape=(256, 256, 3))

  pre_cont = layers.Conv2D(filter_size, (3, 3), padding = "same")(input)

  # context module, level 1
  cont1 = context_module(1, pre_cont)
  cont1 = layers.Add()([pre_cont, cont1])

  # pooling, level 2
  pool2 = pool(2, cont1)

  # context module, level 2
  cont2 = context_module(2, pool2)
  cont2 = layers.Add()([pool2, cont2])

  # pooling, level 3
  pool3 = pool(3, cont2)

  # context module, level 3
  cont3 = context_module(3, pool3)
  cont3 = layers.Add()([pool3, cont3])

  # pooling, level 4
  pool4 = pool(4, cont3)

  # context module, level 4
  cont4 = context_module(4, pool4)
  cont4 = layers.Add()([pool4, cont4])

  # pooling, level 5
  pool5 = pool(5, cont4)

  # context module, level 5
  cont5 = context_module(5, pool5)
  cont5 = layers.Add()([pool5, cont5])

  # MIDDLE
  
  # upsampling module, level 5
  ups5 = upsampling_module(5, cont5)
  ups5 = layers.concatenate([cont4, ups5], axis = 3)

  # localization module, level 4
  loc4 = localization_module(4, ups5)

  # upsampling module, level 4
  ups4 = upsampling_module(4, loc4)
  ups4 = layers.concatenate([cont3, ups4], axis = 3)

  # localization module, level 3
  loc3 = localization_module(3, ups4)

  # upsampling module, level 3
  ups3 = upsampling_module(3, loc3)
  ups3 = layers.concatenate([cont2, ups3], axis = 3)

  # localization module, level 2
  loc2 = localization_module(2, ups3)

  # upsampling module, level 2
  ups2 = upsampling_module(2, loc2)
  ups2 = layers.concatenate([cont1, ups2], axis = 3)

  # post-upscaling
  post_ups = layers.Conv2D(2*filter_size, (3, 3), padding = "same")(ups2)

  # segmentation layer, level 3
  seg3 = tf.keras.layers.Conv2D(4, (3, 3),  activation = "softmax", padding = "same")(loc3)
  seg3 = tf.keras.layers.UpSampling2D()(seg3)
  
  # segmentation layer, level 2
  seg2 = tf.keras.layers.Conv2D(4, (3, 3),  activation = "softmax", padding = "same")(loc2)
  seg2 = layers.Add()([seg3, seg2])
  seg2 = tf.keras.layers.UpSampling2D()(seg2)
  
  # segmentation layer, level 1
  seg1 = tf.keras.layers.Conv2D(4, (3, 3),  activation = "softmax", padding = "same")(post_ups)
  seg1 = layers.Add()([seg2, seg1])

  # output
  output = layers.Conv2D(4, (3,3), padding='same' ,activation="softmax")(seg1)
  
  model = tf.keras.Model(input, output)

  return model

improved_UNET()

